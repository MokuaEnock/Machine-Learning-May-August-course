{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crafting Training Sets\n",
    "\n",
    "#### Overview\n",
    "As mentioned in the intro, the first step in our predictive analytics work is to identify our test andtraining data sets. In this section, we will define key concepts, and run you through a few exerciseson how to use sklearn to achieve this. \n",
    "\n",
    "#### Main Resources\n",
    "> Understanding your variables.\n",
    "\n",
    "First, you must analyze your variables, and determine which variable you want your model to **predict- we will refer to it as the dependent variable**. \n",
    "\n",
    "Next, you must establish which other variables will help you predict your dependent variable. Thesewill be referred to as independent variables.\n",
    "\n",
    "It is important to perform exploratory data analysis to identify if there is a relationship between your dependent and independent variables. This does not mean that your independent variable causes the dependent one, just that they are connected. For example, if we have a dataset on students, we may find variables such as student height, mock exam results, and national exam results. Plotting mock exam results against national exam results,you will see them to roughly take the shape of a line, which makes intuitive sense: Students who do poorly in the mock are likely not to be ready for the national exam, and vice versa.\n",
    "\n",
    "Plotting height against national exam results will probably lead to a much more scattered plot,indicating that there isn't a strong relationship between height and academic performance. \n",
    "\n",
    "\n",
    "Therefore, as we create our training and testing set to predict national exam performance, we willwant to include mock exam performance, but not height. \n",
    "\n",
    "> Why do we need two sets?\n",
    "\n",
    "This is where the machine learning actually happens: The training set includes data on your dependent variable, alongside all independent variables you choose to include. Your supervised learning algorithm will then go through this data set and for a given row try to predict what thedependent variable should be given the independent ones, then adjust its understanding of the process based on how good its prediction was. Over time,  your algorithm will get really good atrecognizing the patterns in your data set. Why do we need the test set then? Well, the test set is not used for training, but to validate howgood the model you've created is at predicting the desired dependent variable. Later this week, we will explore ethical considerations when creating train and test datasets.Remember this though: Your predictive model is only as good as the data you've used to train it.There have been many challenges with training the reading and exercises below will run you through ways to deal with them.\n",
    "\n",
    "\n",
    "#### Additional learning links \n",
    "\n",
    "Here are additional learning materails for this lesson:\n",
    "\n",
    "1. [How Do You Know You Have Enough Training Data?](https://towardsdatascience.com/how-do-you-know-you-have-enough-training-data-ad9b1fd679ee)\n",
    "\n",
    "2. [Google ‘fixed’ its racist algorithm by removing gorillas from its image-labeling tech](https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai)\n",
    "\n",
    "\n",
    "## 2. Practice\n",
    "\n",
    "Our major goal here, is to predict how a student will perform in the national exam by using their mock exam scores.There's a few steps we need to do to achieve this.\n",
    "\n",
    "First, we need split the dataset into training and test datasets so that we can train the model to predict our desired outcome\n",
    "\n",
    "After splitting the dataset , we are going to employ a method for training the datasets.\n",
    "\n",
    "The following example will be split into two parts; the first being how to split the dataset into train and test datasets. The second part is how to train the data using linear regression.\n",
    "\n",
    "\n",
    "In this example, we are going to learn how to split a dataset into train and test sets so that we can start training our model. We will first show a naive way of splitting a dataset then continue to show different ways of efficiently splitting the dataset.\n",
    "\n",
    "The dataset we are going to use will comprise of 1000 students exam data from both public and private schools in Kenya. 50% of this data is from public school and the other 50% is from private schools. We need to maintain this proportion when creating our sample dataset.\n",
    "\n",
    "**Naive splitting:**\n",
    "\n",
    "- Show a simple 3 column table, with 1 dependent 1 independent variable. The independent variable is the Mock exam column and the dependent variable is National exam column.\n",
    "- use simple splits to create 2 datasets, one for train, one for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant librares and packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mock_result</th>\n",
       "      <th>school_type</th>\n",
       "      <th>national_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mock_result school_type  national_result\n",
       "0           27      PUBLIC               55\n",
       "1           60     PRIVATE               35\n",
       "2           57      PUBLIC               39\n",
       "3           52      PUBLIC               39\n",
       "4           44      PUBLIC               63"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"./data/student_exam_data.csv\")\n",
    "\n",
    "# display teh first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:700\n",
      "test:300\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset into train and test sets.\n",
    "# we will split the dataset such that we have the first 700 entries of our dataset as train and the rest 300 entries as test\n",
    "\n",
    "train = data[:700]\n",
    "\n",
    "# Drop all the indexes of the train data we created above from the main data set then store the remaining data in a variable called test\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Confirm that the train and test dataset have out desired length\n",
    "print(\"train:\" + str(len(train)))\n",
    "print(\"test:\"+ str(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing the sets**:\n",
    "How similar are the training and test datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_type\n",
      "PUBLIC     450\n",
      "PRIVATE    250\n",
      "Name: count, dtype: int64\n",
      "*************************\n",
      "school_type\n",
      "PRIVATE    250\n",
      "PUBLIC      50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's analyse the training and the test dataset and see if the right proportions.\n",
    "# Ideally, we want both of our training and test datasets to have a 50-50 apportionment of private and public schools\n",
    "\n",
    "# Check the apportionment of Private and Public schools in the train data set\n",
    "train_count=train['school_type'].value_counts()\n",
    "\n",
    "# Check the apportionment of Private and Public in the test data set\n",
    "test_count=test['school_type'].value_counts()\n",
    "\n",
    "# Print out the apportionment of private and public schools in both train and test dataset\n",
    "print(train_count)\n",
    "print('*************************')\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see,  the number of public schools in the train dataset is 450 while that of private schools is 250.This translates to 65% and 35%  respectively, which is not the proportion we are aiming for.\n",
    "\n",
    "Similarly, in the test dataset there are 250 public schools and 50 private schools. This in turn translates to 84% and 16% respectively. Again, this is not quite the proportion we were aiming for.\n",
    "\n",
    "In conclusion this differs greatly from what we are aiming for, which is to have an equal proportion of private schools and public school in both the train/test dataset.That is, to have 50% of public school and 50% of private school in both the train and test dataset.\n",
    "\n",
    "This is why we termed this as a naive way of splitting the dataset because it does not reflect the populations initial proportion.\n",
    "\n",
    "To achieve the proportion we want, we will employ one of the sampling techniques we covered in module 1\n",
    "\n",
    "**Sampling**:\n",
    "\n",
    "Remember module 1 stuff, let's do some stratified sampling, and see that our test / train are now similar to each other (public VS private student representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_type\n",
      "PRIVATE    350\n",
      "PUBLIC     350\n",
      "Name: count, dtype: int64\n",
      "*************************************************\n",
      "school_type\n",
      "PRIVATE    150\n",
      "PUBLIC     150\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_692114/2020882610.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_strat_datset = data.groupby('school_type', group_keys=False).apply(lambda grouped_subset : grouped_subset.sample(frac=0.7))\n"
     ]
    }
   ],
   "source": [
    "# Using the Stratified technique we want to split the dataset in such a way that 70% of our dataset will be train set and 30% will be test set. Furthermore, the proportion of public and private schools should be equal in both the train and test dataset. For example, in train dataset we should have 350 public schools and 350 private schools represented. The same goes for the test dataset, we expect to have 150 private schools and 150 private schools.\n",
    "\n",
    "# Stratified train sample\n",
    "train_strat_datset = data.groupby('school_type', group_keys=False).apply(lambda grouped_subset : grouped_subset.sample(frac=0.7))\n",
    "\n",
    "# preview the stratified train dataset\n",
    "train_strat_datset\n",
    "\n",
    "# Stratified test sample\n",
    "test_strat_dataset = data.drop(train_strat_datset.index)\n",
    "\n",
    "# Preview the stratified test dataset\n",
    "test_strat_dataset\n",
    "\n",
    "# Print out the proprortion of private vs public schools in both train and test dataset\n",
    "test_strat_count=test_strat_dataset['school_type'].value_counts()\n",
    "train_strat_count=train_strat_datset['school_type'].value_counts()\n",
    "\n",
    "print(train_strat_count)\n",
    "print('*************************************************')\n",
    "print(test_strat_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
